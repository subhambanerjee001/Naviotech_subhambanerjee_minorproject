import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import tkinter as tk
from tkinter import filedialog, Label, Button
from PIL import Image, ImageTk
from datasets import load_dataset

def load_data(data_dir, img_size=32):
    images, labels = [], []
    classes = len(os.listdir(data_dir))

    for label in range(classes):
        folder = os.path.join(data_dir, str(label))
        if not os.path.isdir(folder):
            continue
        for file in os.listdir(folder):
            img_path = os.path.join(folder, file)
            try:
                img = cv2.imread(img_path)
                img = cv2.resize(img, (img_size, img_size))
                images.append(img)
                labels.append(label)
            except Exception as e:
                print("Error loading image:", e)

    return np.array(images), np.array(labels), classes

def preprocess_data(images, labels, classes):
    images = images.astype("float32") / 255.0
    labels = to_categorical(labels, classes)
    return images, labels


def build_model(input_shape, classes):
    model = Sequential([
        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),
        MaxPooling2D((2,2)),

        Conv2D(64, (3,3), activation='relu'),
        MaxPooling2D((2,2)),

        Conv2D(128, (3,3), activation='relu'),
        MaxPooling2D((2,2)),

        Flatten(),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(classes, activation='softmax')
    ])

    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

def train_model(model, X_train, y_train, X_val, y_val, epochs=15):
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=epochs,
        batch_size=64,
        verbose=1
    )
    return history


def plot_history(history):
    plt.figure(figsize=(12,4))

    plt.subplot(1,2,1)
    plt.plot(history.history['accuracy'], label='Train Acc')
    plt.plot(history.history['val_accuracy'], label='Val Acc')
    plt.legend()
    plt.title("Accuracy")

    plt.subplot(1,2,2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.legend()
    plt.title("Loss")

    plt.show()


def predict_image(model, img_path, img_size=32):
    img = cv2.imread(img_path)
    img = cv2.resize(img, (img_size, img_size))
    img = np.expand_dims(img, axis=0) / 255.0
    prediction = model.predict(img)
    return np.argmax(prediction), np.max(prediction)

class TrafficSignGUI:
    def __init__(self, model, classes):
        self.model = model
        self.classes = classes
        self.root = tk.Tk()
        self.root.title( "Traffic Sign Classifier")
        self.root.geometry("500x500")
        self.label = Label(self.root, text="Upload a Traffic Sign Image", font=("Arial", 16))
        self.label.pack(pady=20)
        self.img_label = Label(self.root)
        self.img_label.pack()
        self.result_label = Label(self.root, text="", font=("Arial", 14))
        self.result_label.pack(pady=20)
        Button(self.root, text="Upload Image", command=self.upload_image).pack()
        self.root.mainloop()

    def upload_image(self):
        file_path = filedialog.askopenfilename()
        if file_path:
            pred_class, confidence = predict_image(self.model, file_path)
            img = Image.open(file_path)
            img = img.resize((200,200))
            img = ImageTk.PhotoImage(img)
            self.img_label.config(image=img)
            self.img_label.image = img
            self.result_label.config(
                text=f"Predicted Class: {pred_class}\nConfidence: {confidence*100:.2f}%"
            )
if __name__ == "__main__":
    ds = load_dataset("tanganke/gtsrb")
    images = []
    labels = []
    classes = 0
    img_size = 32
    if "train" in ds:
        classes = ds["train"].features["label"].num_classes
        for item in ds["train"]:
            
            img = np.array(item["image"])
            img = cv2.resize(img, (img_size, img_size))
            images.append(img)
            labels.append(item["label"])

    images = np.array(images)
    labels = np.array(labels)

    print(" Dataset loaded:", images.shape, labels.shape, "Classes:", classes)

    X, y = preprocess_data(images, labels, classes)
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    model = build_model((img_size, img_size, 3), classes) # Update input shape
    history = train_model(model, X_train, y_train, X_val, y_val, epochs=15)

    plot_history(history)


    y_pred = model.predict(X_val)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true = np.argmax(y_val, axis=1)

    print(" Classification Report:\n", classification_report(y_true, y_pred_classes))
    print(" Confusion Matrix:\n", confusion_matrix(y_true, y_pred_classes))

